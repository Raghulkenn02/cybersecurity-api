import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os

class CybersecurityModel:
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        
    def create_sample_data(self, n_samples=10000):
        """Create more detailed sample cybersecurity data"""
        np.random.seed(42)
        
        # Create more realistic features
        features = {
            'packet_size': np.random.normal(500, 150, n_samples),
            'connection_duration': np.random.exponential(100, n_samples),
            'byte_rate': np.random.normal(1000, 300, n_samples),
            'packet_rate': np.random.normal(50, 15, n_samples),
            'port_number': np.random.randint(1, 65535, n_samples),
            'protocol_type': np.random.randint(0, 3, n_samples),  # TCP, UDP, ICMP
            'bytes_transferred': np.random.exponential(5000, n_samples)
        }
        
        # Create threat labels with specific patterns
        labels = np.zeros(n_samples)
        
        # Simulate threats based on patterns
        for i in range(n_samples):
            # High byte rate with short duration might indicate DDoS
            if features['byte_rate'][i] > 1500 and features['connection_duration'][i] < 50:
                labels[i] = 1
            # Unusual port with high bytes transferred might indicate data exfiltration
            elif features['port_number'][i] > 50000 and features['bytes_transferred'][i] > 10000:
                labels[i] = 1
            # Add some randomness
            elif np.random.random() < 0.1:
                labels[i] = 1
                
        df = pd.DataFrame(features)
        df['label'] = labels
        
        return df
    
    def build_model(self, input_shape):
        """Create a more sophisticated model architecture"""
        model = tf.keras.Sequential([
            # Input layer
            tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape,
                                kernel_regularizer=tf.keras.regularizers.l2(0.01)),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.3),
            
            # Hidden layers
            tf.keras.layers.Dense(32, activation='relu',
                                kernel_regularizer=tf.keras.regularizers.l2(0.01)),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.2),
            
            tf.keras.layers.Dense(16, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            
            # Output layer
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
        )
        
        return model
    
    def train(self, save_path='cybersecurity_model'):
        """Train the model with sample data"""
        print("Preparing training data...")
        data = self.create_sample_data()
        
        # Split features and labels
        X = data.drop('label', axis=1)
        y = data['label']
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Scale the features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Build and train the model
        print("\nTraining model...")
        self.model = self.build_model(input_shape=(X_train.shape[1],))
        
        # Add callbacks
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )
        
        history = self.model.fit(
            X_train_scaled, y_train,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )
        
        # Evaluate the model
        print("\nEvaluating model...")
        test_results = self.model.evaluate(X_test_scaled, y_test, verbose=0)
        print(f"Test Accuracy: {test_results[1]:.4f}")
        print(f"Test Precision: {test_results[2]:.4f}")
        print(f"Test Recall: {test_results[3]:.4f}")
        
        # Save the model
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        self.model.save(f"{save_path}/model.h5")
        print(f"\nModel saved to {save_path}/model.h5")
        
        return history
    
    def predict(self, input_data):
        """Make predictions on new data"""
        if self.model is None:
            raise ValueError("Model hasn't been trained yet!")
        
        # Scale the input data
        scaled_data = self.scaler.transform(input_data)
        
        # Make predictions
        predictions = self.model.predict(scaled_data)
        return predictions

def main():
    # Create and train the model
    print("Starting Cybersecurity Model Training Pipeline...")
    model = CybersecurityModel()
    history = model.train()
    
    # Test the model with some sample data
    print("\nTesting prediction on sample data...")
    test_data = pd.DataFrame({
        'packet_size': [450],
        'connection_duration': [150],
        'byte_rate': [1600],
        'packet_rate': [45],
        'port_number': [55000],
        'protocol_type': [1],
        'bytes_transferred': [12000]
    })
    
    prediction = model.predict(test_data)
    print(f"Threat probability for test data: {prediction[0][0]:.4f}")

if __name__ == "__main__":
    main()
